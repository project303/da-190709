{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 05 - TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Release: 1.1907.1602"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepocessing function from previous labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_clean(text):\n",
    "    \n",
    "    #tokenisasi\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word\n",
    "        in nltk.word_tokenize(sent)]\n",
    "    \n",
    "    #clean token from numeric and other character like puntuation\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_text):\n",
    "    \n",
    "    cleaned_token = []\n",
    "    for token in tokenized_text:\n",
    "        if token not in stopwords:\n",
    "            cleaned_token.append(token)\n",
    "            \n",
    "    return cleaned_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_text(tokenized_text):\n",
    "    \n",
    "    #stem using Sastrawi StemmerFactory \n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "\n",
    "    stems = []\n",
    "    for token in tokenized_text:\n",
    "        stems.append(stemmer.stem(token))\n",
    "\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \n",
    "    prep01 = tokenize_clean(text)\n",
    "    prep02 = remove_stopwords(prep01)\n",
    "    prep03 = stemming_text(prep02)\n",
    "    \n",
    "    return prep03\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 01 - Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "files.append(\"Sekelompok ibu dan kaum perempuan duduk beralaskan rumput lapangan sambil fokus menganyam bambu yang ia genggam ditangan.\")\n",
    "files.append(\"Sebagian besar masyarakat rupanya tak mau melewatkan waktu begitu  saja untuk meratapi erupsi.\")\n",
    "files.append(\"Lombok memang memiliki sejuta pesona yang mampu menyedot perhatian orang untuk datang berwisata.\")\n",
    "files.append(\"Perempuan yang bergelut di dunia kerelawanan akan belajar caranya bertanggung jawab bagi sendiri dan orang lain.\")\n",
    "files.append(\"Kami berkoordinasi dan melapor pada posko relawan, kami berkomitmen  siap membantu dengan siaga 24 jam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 02 - Corpus preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare corpus, load it into dictionary\n",
    "token_dict = {}\n",
    "i = 0\n",
    "for t in files:\n",
    "    filename = \"file\" + str(i)\n",
    "    token_dict[filename] = t\n",
    "    i = i + 1\n",
    "\n",
    "token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform tf-idf vectorization\n",
    "tfidf = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words = stopwords,\n",
    "                                 use_idf=True, tokenizer=text_preprocessing, ngram_range=(1,3))\n",
    "\n",
    "\n",
    "tfs = tfidf.fit_transform(token_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# print idf values\n",
    "df_idf = pd.DataFrame(tfidf.idf_, index=tfidf.get_feature_names(),columns=[\"idf\"])\n",
    " \n",
    "# sort ascending\n",
    "df_idf.sort_values(by=['idf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 03 - TF-IDF Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = 'Di kejauhan tampak seorang relawan pria dari Lombok sedang berjalan.'\n",
    "response = tfidf.transform([str1])\n",
    "\n",
    "#show result\n",
    "feature_names = tfidf.get_feature_names()\n",
    "for col in response.nonzero()[1]:\n",
    "    print (feature_names[col], ' - ', response[0, col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (text_preprocessing(str1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Smaller Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of text documents\n",
    "text = [\"Sebagian besar masyarakat rupanya tak mau melewatkan waktu begitu  saja untuk meratapi erupsi.\",\n",
    "        \"Masyarakat tak mau erupsi\",\n",
    "        \"Rupanya waktu erupsi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transform\n",
    "vectorizer = TfidfVectorizer(tokenizer=text_preprocessing)\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print idf values\n",
    "df_idf = pd.DataFrame(vectorizer.idf_, index=vectorizer.get_feature_names(),columns=[\"idf\"])\n",
    " \n",
    "# sort ascending\n",
    "df_idf.sort_values(by=['idf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode document\n",
    "vector = vectorizer.transform([text[0]])\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
